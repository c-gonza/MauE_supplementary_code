{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this notebook is defining how the cxc motifs are found\n",
    "it also determines if the motif is past inside or before the IPR region \n",
    "This generated a annotated data set which I later added information about MauA into after the fact in notebook 2_4\n",
    "\n",
    "This did not change this annotation and there was no filtering at that step so it was tacked on to the first dataset and moved\n",
    "forward\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849623ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import sys, errno, re, json, ssl\n",
    "from urllib import request\n",
    "from urllib.error import HTTPError\n",
    "from time import sleep\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from Bio import Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in the full raw data set\n",
    "FBDS = pd.read_excel(r'C:\\PATH\\1_full_set_raw_10_2024.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee369859",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "below I am using the same function as before so that I can pull the IPR deliminating regions in the sequence\n",
    "and then search for a CXC in that region. This was only done for entries with MauE. Everything else will show as NaN in\n",
    "the dataframe.\n",
    "'''\n",
    "\n",
    "def fetch_data(BASE_URL):\n",
    "\n",
    "    context = ssl._create_unverified_context()\n",
    "    next_url = BASE_URL\n",
    "    returned_df = pd.DataFrame()  \n",
    "    \n",
    "    while next_url:\n",
    "        try:\n",
    "            req = request.Request(next_url, headers={\"Accept\": \"application/json\"})\n",
    "            res = request.urlopen(req, context=context)\n",
    "\n",
    "            if res.status == 408:\n",
    "                sleep(61)\n",
    "                continue\n",
    "            elif res.status == 204:\n",
    "                break\n",
    "\n",
    "            payload = json.loads(res.read().decode())\n",
    "            next_url = payload.get(\"next\", None)\n",
    "                \n",
    "            for item in payload[\"results\"]:\n",
    "                IPR = 'IPR'\n",
    "                test_string =  item['metadata']['accession']\n",
    "                accession = item['proteins'][0]['accession']\n",
    "                returned_df.at[0,'Accession'] = accession\n",
    "                if IPR in test_string:\n",
    "                    #print('accession is IPR entry')\n",
    "                    #print('num fragments: ', len(item['proteins'][0]['entry_protein_locations'][0]['fragments']))\n",
    "                    for i in item['proteins'][0]['entry_protein_locations'][0]['fragments']:\n",
    "                        region_string = str(i['start']) + '_'+str(i['end'])\n",
    "                        #print(region_string)\n",
    "                        col_name = test_string + '_{}'.format(item['proteins'][0]['entry_protein_locations'][0]['fragments'].index(i))\n",
    "                        #print(col_name)\n",
    "                        returned_df.at[0,col_name] = region_string\n",
    "                \n",
    "            \n",
    "                    \n",
    "                else:\n",
    "                    continue\n",
    "            #display(returned_df)\n",
    "         \n",
    "                \n",
    "            \n",
    "\n",
    "            sleep(1)  \n",
    "\n",
    "        except HTTPError as e:\n",
    "            if e.code == 408:\n",
    "                sleep(61)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Error occurred: {e}\")\n",
    "                break\n",
    "\n",
    "    return returned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section pulls for maue only\n",
    "base = \"https://www.ebi.ac.uk/interpro/api/entry/all/protein/\"\n",
    "db1 = 'unreviewed/'\n",
    "db2 = 'reviewed/'\n",
    "db3 = 'UniProt/'\n",
    "mask = FBDS['IPR009908'] == 'IPR009908'\n",
    "FBDS2 = FBDS.loc[mask]\n",
    "accession_list = list(FBDS2['Accession'])\n",
    "print(len(accession_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb168354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small check\n",
    "print(accession_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section creates a dataframe using fetch_data that has every IPR associated with each MAUE entry in the \n",
    "#full bacterial dataset FBDS\n",
    "#this includes the IPR start and end which will be used to get the active site motif metadata\n",
    "\n",
    "IPR_info_FBDS = pd.DataFrame()\n",
    "for i in accession_list:\n",
    "    try:\n",
    "        url= base+db1+i\n",
    "        #print(url)\n",
    "        new_row = fetch_data(url)\n",
    "        IPR_info_FBDS = pd.concat([IPR_info_FBDS,new_row])\n",
    "    except:\n",
    "        try:\n",
    "            url= base+db2+i\n",
    "            new_row = fetch_data(url)\n",
    "            IPR_info_FBDS = pd.concat([IPR_info_FBDS,new_row])\n",
    "        except:\n",
    "            try:\n",
    "                \n",
    "                url= base+db3+i\n",
    "                new_row = fetch_data(url)\n",
    "                IPR_info_FBDS = pd.concat([IPR_info_FBDS,new_row])\n",
    "            except:\n",
    "                print('not found')\n",
    "                \n",
    "IPR_df2 = IPR_info_FBDS.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small check\n",
    "from IPython.display import display\n",
    "display(IPR_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save metadata\n",
    "IPR_df2.to_excel(r'C:\\PATH\\2b_IPR_metadata_for_all_maue.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now that we have the full raw data set and the metadata associated with the IPR\n",
    "we can search for the active site\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this sets the accession as the index of the fbds then searches the accession from IPR_df2 \n",
    "\n",
    "FBDS3 = FBDS.set_index('Accession')\n",
    "display(FBDS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the columns\n",
    "\n",
    "for col in ['CXC_at_all', 'CXC_past','CXC_before','CXC_inside_IPR']:\n",
    "    if col not in FBDS.columns:\n",
    "        FBDS3[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I used this to add metadata on the location of the cxc in the sequence and the center amino acid\n",
    "## you need to filter cxc in the motif but there is no X amino acid data because the logo plot covers that\n",
    "#searching by IPR_df2 because that contains all the entries for maue that I could pull the metadata on and \n",
    "#leaves out the entries that cant be found but were there in the fasta pull (I checked those and those entries are empty for metadata)\n",
    "\n",
    "\n",
    "\n",
    "for ind in IPR_df2.index:\n",
    "    accession = IPR_df2.at[ind, 'Accession']\n",
    "    acc_upper = accession.upper()\n",
    "    print(accession, acc_upper)\n",
    "    seq = FBDS3.at[acc_upper, 'Sequence']\n",
    "    print(seq)\n",
    "    location_string = IPR_df2.at[ind,'IPR009908_0']\n",
    "    try:\n",
    "        \n",
    "        start = int(location_string.split('_')[0])\n",
    "        end = int(location_string.split('_')[1])\n",
    "\n",
    "   \n",
    "\n",
    "        # Detect all CXC motifs\n",
    "        matches = re.finditer(r'C[A-Z]C', seq)\n",
    "        for match in matches:\n",
    "            loc = match.start()\n",
    "            motif = match.group()\n",
    "        \n",
    "\n",
    "            if (loc >= start) and (loc <= end):\n",
    "                FBDS3.at[acc_upper,'CXC_at_all'] += 1\n",
    "                FBDS3.at[acc_upper,'CXC_inside_IPR'] += 1\n",
    "            \n",
    "            elif loc > end:\n",
    "                FBDS3.at[acc_upper,'CXC_at_all'] += 1\n",
    "                FBDS3.at[acc_upper,'CXC_past'] += 1\n",
    "           \n",
    "            elif loc < start:\n",
    "                FBDS3.at[acc_upper,'CXC_at_all'] += 1\n",
    "                FBDS3.at[acc_upper,'CXC_before'] += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe548572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataframe\n",
    "display(FBDS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the FBDS with the CXC metadata\n",
    "#now it is ready to filter by species and phylum \n",
    "#this is where the original CXC annotation happened, and MauA was added in the second notebook after the fact since \n",
    "#it did not change any annotations or filtering at that step\n",
    "FBDS3.to_excel(r'C:\\PATH\\2_FBDS_annotated_CXC.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ffd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "its worth noting that the regex term will fill the cxc_at_all tab with the number of cxc hits it has. depending on how you want\n",
    "to filter down you can then process the rest of the data set as we have. but It is our opinion that any MauE with a cxc at all \n",
    "within the IPR region is an active candidate for the data analysis. if the cxc motif is outside the IPR region or if there is \n",
    "no cxc motif it is regarded as a false positive pull from the interpro database and is not used in the analysis.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
